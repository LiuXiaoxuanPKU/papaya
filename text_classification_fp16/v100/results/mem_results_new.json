{"network": "bert-large-cased", "algorithm": null, "batch_size": 4, "layer_num": 48, "hidden_size": 1024, "peak": 12412.26123, "total": 12398.783661, "activation": 2692.912109, "model_size": 9705.859344, "workspace_size": 13.47757, "tstamp": 1665349375.64}
{"network": "bert-large-cased", "algorithm": null, "batch_size": 4, "layer_num": 24, "hidden_size": 1024, "peak": 6455.19873, "total": 6441.721161, "activation": 1348.724609, "model_size": 5092.984344, "workspace_size": 13.47757, "tstamp": 1665351161.78}
{"network": "bert-large-cased", "algorithm": null, "batch_size": 12, "layer_num": 24, "hidden_size": 1024, "peak": 8085.533691, "total": 8061.1586, "activation": 2955.162109, "model_size": 5105.960846, "workspace_size": 24.375092, "tstamp": 1665351203.23}
{"network": "bert-large-cased", "algorithm": null, "batch_size": 20, "layer_num": 24, "hidden_size": 1024, "peak": 9627.501953, "total": 9580.096039, "activation": 4438.099609, "model_size": 5141.937347, "workspace_size": 47.405914, "tstamp": 1665351245.24}
{"network": "bert-large-cased", "algorithm": null, "batch_size": 28, "layer_num": 24, "hidden_size": 1024, "peak": 11178.854004, "total": 11118.033478, "activation": 6019.537109, "model_size": 5098.413849, "workspace_size": 60.820526, "tstamp": 1665351286.99}
{"network": "bert-large-cased", "algorithm": null, "batch_size": 36, "layer_num": 24, "hidden_size": 1024, "peak": 12763.26416, "total": 12683.970917, "activation": 7562.474609, "model_size": 5121.39035, "workspace_size": 79.293243, "tstamp": 1665351329.17}
{"network": "bert-large-cased", "algorithm": null, "batch_size": 44, "layer_num": 24, "hidden_size": 1024, "peak": 14365.674316, "total": 14267.408356, "activation": 9174.412109, "model_size": 5092.866852, "workspace_size": 98.265961, "tstamp": 1665351371.17}
{"network": "bert-base-cased", "algorithm": null, "batch_size": 4, "layer_num": 12, "hidden_size": 768, "peak": 2180.327148, "total": 2172.717255, "activation": 506.248047, "model_size": 1666.457001, "workspace_size": 7.609894, "tstamp": 1665351600.46}
{"network": "bert-base-cased", "algorithm": null, "batch_size": 12, "layer_num": 12, "hidden_size": 768, "peak": 2771.542969, "total": 2753.078522, "activation": 1098.359375, "model_size": 1654.683502, "workspace_size": 18.464447, "tstamp": 1665351635.62}
{"network": "bert-base-cased", "algorithm": null, "batch_size": 20, "layer_num": 12, "hidden_size": 768, "peak": 3363.003906, "total": 3326.814789, "activation": 1654.470703, "model_size": 1672.285004, "workspace_size": 36.189117, "tstamp": 1665351671.77}
{"network": "bert-base-cased", "algorithm": null, "batch_size": 28, "layer_num": 12, "hidden_size": 768, "peak": 4049.089844, "total": 3998.551056, "activation": 2305.332031, "model_size": 1693.136505, "workspace_size": 50.538788, "tstamp": 1665351706.54}
{"network": "bert-base-cased", "algorithm": null, "batch_size": 36, "layer_num": 12, "hidden_size": 768, "peak": 4629.004395, "total": 4567.162323, "activation": 2872.693359, "model_size": 1694.363007, "workspace_size": 61.842072, "tstamp": 1665351742.38}
{"network": "bert-base-cased", "algorithm": null, "batch_size": 44, "layer_num": 12, "hidden_size": 768, "peak": 5189.227051, "total": 5115.02359, "activation": 3430.304688, "model_size": 1684.589508, "workspace_size": 74.203461, "tstamp": 1665351777.6}
{"network": "bert-base-cased", "algorithm": null, "batch_size": 52, "layer_num": 12, "hidden_size": 768, "peak": 5822.824707, "total": 5734.509857, "activation": 4061.791016, "model_size": 1672.56601, "workspace_size": 88.31485, "tstamp": 1665351813.52}
{"network": "bert-base-cased", "algorithm": null, "batch_size": 60, "layer_num": 12, "hidden_size": 768, "peak": 6398.672363, "total": 6296.746124, "activation": 4597.777344, "model_size": 1698.792511, "workspace_size": 101.926239, "tstamp": 1665351849.83}
{"network": "bert-base-cased", "algorithm": null, "batch_size": 64, "layer_num": 12, "hidden_size": 768, "peak": 6638.783691, "total": 6532.239258, "activation": 4831.020508, "model_size": 1701.030762, "workspace_size": 106.544434, "tstamp": 1665351885.63}
{"network": "bert-base-cased", "algorithm": null, "batch_size": 72, "layer_num": 12, "hidden_size": 768, "peak": 7264.882324, "total": 7142.85199, "activation": 5457.632324, "model_size": 1685.007751, "workspace_size": 122.030334, "tstamp": 1665351920.94}
{"network": "bert-base-cased", "algorithm": null, "batch_size": 80, "layer_num": 12, "hidden_size": 768, "peak": 7808.22998, "total": 7673.588257, "activation": 5998.368652, "model_size": 1674.984253, "workspace_size": 134.641724, "tstamp": 1665351956.81}
{"network": "bert-base-cased", "algorithm": null, "batch_size": 88, "layer_num": 12, "hidden_size": 768, "peak": 8438.952637, "total": 8288.949524, "activation": 6618.97998, "model_size": 1669.710754, "workspace_size": 150.003113, "tstamp": 1665351991.72}
{"network": "bert-base-cased", "algorithm": null, "batch_size": 96, "layer_num": 12, "hidden_size": 768, "peak": 8957.425293, "total": 8797.560791, "activation": 7141.966309, "model_size": 1655.312256, "workspace_size": 159.864502, "tstamp": 1665352027.12}
{"network": "bert-base-cased", "algorithm": null, "batch_size": 104, "layer_num": 12, "hidden_size": 768, "peak": 9636.272949, "total": 9459.297058, "activation": 7798.702637, "model_size": 1660.288757, "workspace_size": 176.975891, "tstamp": 1665352062.69}
{"network": "bert-base-cased", "algorithm": null, "batch_size": 112, "layer_num": 12, "hidden_size": 768, "peak": 10176.495605, "total": 9988.033325, "activation": 8322.063965, "model_size": 1665.640259, "workspace_size": 188.46228, "tstamp": 1665352097.78}
{"network": "bert-base-cased", "algorithm": null, "batch_size": 120, "layer_num": 12, "hidden_size": 768, "peak": 10805.620605, "total": 10601.671936, "activation": 8927.800293, "model_size": 1673.519104, "workspace_size": 203.948669, "tstamp": 1665352132.65}
{"network": "bert-base-cased", "algorithm": null, "batch_size": 128, "layer_num": 12, "hidden_size": 768, "peak": 11351.241699, "total": 11137.306641, "activation": 9468.337402, "model_size": 1668.593262, "workspace_size": 213.935059, "tstamp": 1665352168.77}
{"network": "bert-base-cased", "algorithm": null, "batch_size": 136, "layer_num": 12, "hidden_size": 768, "peak": 11997.066895, "total": 11765.396912, "activation": 10102.801758, "model_size": 1662.195251, "workspace_size": 231.669983, "tstamp": 1665352205.02}
{"network": "bert-base-cased", "algorithm": null, "batch_size": 144, "layer_num": 12, "hidden_size": 768, "peak": 12573.664551, "total": 12330.883179, "activation": 10643.885742, "model_size": 1686.574097, "workspace_size": 242.781372, "tstamp": 1665352240.53}
{"network": "bert-base-cased", "algorithm": null, "batch_size": 152, "layer_num": 12, "hidden_size": 768, "peak": 13187.609863, "total": 12929.717102, "activation": 11256.49707, "model_size": 1672.773254, "workspace_size": 257.892761, "tstamp": 1665352275.81}
{"network": "bert-base-cased", "algorithm": null, "batch_size": 160, "layer_num": 12, "hidden_size": 768, "peak": 13727.984863, "total": 13459.605713, "activation": 11786.385742, "model_size": 1672.749756, "workspace_size": 268.37915, "tstamp": 1665352311.32}
{"network": "bert-base-cased", "algorithm": null, "batch_size": 168, "layer_num": 12, "hidden_size": 768, "peak": 14381.83252, "total": 14095.59198, "activation": 12419.020508, "model_size": 1676.07782, "workspace_size": 286.24054, "tstamp": 1665352347.33}
{"network": "roberta-base", "algorithm": null, "batch_size": 4, "layer_num": 12, "hidden_size": 768, "peak": 2430.144531, "total": 2423.416473, "activation": 503.754883, "model_size": 1919.65329, "workspace_size": 6.728058, "tstamp": 1665352455.81}
{"network": "roberta-base", "algorithm": null, "batch_size": 12, "layer_num": 12, "hidden_size": 768, "peak": 3022.985352, "total": 3004.541412, "activation": 1097.629883, "model_size": 1906.887604, "workspace_size": 18.443939, "tstamp": 1665352484.81}
{"network": "roberta-base", "algorithm": null, "batch_size": 20, "layer_num": 12, "hidden_size": 768, "peak": 3615.946289, "total": 3579.791351, "activation": 1654.004883, "model_size": 1925.746918, "workspace_size": 36.154938, "tstamp": 1665352514.12}
{"network": "roberta-base", "algorithm": null, "batch_size": 28, "layer_num": 12, "hidden_size": 768, "peak": 4304.032227, "total": 4252.79129, "activation": 2304.254883, "model_size": 1948.481232, "workspace_size": 51.240936, "tstamp": 1665352543.52}
{"network": "roberta-base", "algorithm": null, "batch_size": 36, "layer_num": 12, "hidden_size": 768, "peak": 4880.946777, "total": 4818.291229, "activation": 2868.129883, "model_size": 1950.090546, "workspace_size": 62.655548, "tstamp": 1665352573.25}
{"network": "roberta-base", "algorithm": null, "batch_size": 44, "layer_num": 12, "hidden_size": 768, "peak": 5440.669434, "total": 5366.916168, "activation": 3430.754883, "model_size": 1936.07486, "workspace_size": 73.753265, "tstamp": 1665352602.88}
{"network": "roberta-base", "algorithm": null, "batch_size": 52, "layer_num": 12, "hidden_size": 768, "peak": 6076.14209, "total": 5986.916107, "activation": 4060.879883, "model_size": 1925.934174, "workspace_size": 89.225983, "tstamp": 1665352632.72}
{"network": "roberta-base", "algorithm": null, "batch_size": 60, "layer_num": 12, "hidden_size": 768, "peak": 6656.489746, "total": 6554.791046, "activation": 4603.629883, "model_size": 1951.043488, "workspace_size": 101.6987, "tstamp": 1665352662.49}
{"network": "roberta-base", "algorithm": null, "batch_size": 64, "layer_num": 12, "hidden_size": 768, "peak": 6888.976074, "total": 6782.541016, "activation": 4830.629883, "model_size": 1951.785645, "workspace_size": 106.435059, "tstamp": 1665352692.72}
{"network": "roberta-base", "algorithm": null, "batch_size": 72, "layer_num": 12, "hidden_size": 768, "peak": 7517.699707, "total": 7394.917419, "activation": 5457.505371, "model_size": 1937.270447, "workspace_size": 122.782288, "tstamp": 1665352722.2}
{"network": "roberta-base", "algorithm": null, "batch_size": 80, "layer_num": 12, "hidden_size": 768, "peak": 8059.422363, "total": 7924.917358, "activation": 5996.630371, "model_size": 1928.129761, "workspace_size": 134.505005, "tstamp": 1665352752.38}
{"network": "roberta-base", "algorithm": null, "batch_size": 88, "layer_num": 12, "hidden_size": 768, "peak": 8694.64502, "total": 8544.792297, "activation": 6621.630371, "model_size": 1922.989075, "workspace_size": 149.852722, "tstamp": 1665352782.44}
{"network": "roberta-base", "algorithm": null, "batch_size": 96, "layer_num": 12, "hidden_size": 768, "peak": 9210.742676, "total": 9050.042236, "activation": 7142.255371, "model_size": 1907.598389, "workspace_size": 160.700439, "tstamp": 1665352812.65}
{"network": "roberta-base", "algorithm": null, "batch_size": 104, "layer_num": 12, "hidden_size": 768, "peak": 9884.965332, "total": 9708.167175, "activation": 7794.630371, "model_size": 1913.332703, "workspace_size": 176.798157, "tstamp": 1665352842.46}
{"network": "roberta-base", "algorithm": null, "batch_size": 112, "layer_num": 12, "hidden_size": 768, "peak": 10425.687988, "total": 10237.417114, "activation": 8317.755371, "model_size": 1919.442017, "workspace_size": 188.270874, "tstamp": 1665352872.57}
{"network": "roberta-base", "algorithm": null, "batch_size": 120, "layer_num": 12, "hidden_size": 768, "peak": 11055.160645, "total": 10851.667053, "activation": 8925.755371, "model_size": 1925.676331, "workspace_size": 203.493591, "tstamp": 1665352902.65}
{"network": "roberta-base", "algorithm": null, "batch_size": 128, "layer_num": 12, "hidden_size": 768, "peak": 11604.133301, "total": 11390.416992, "activation": 9468.005371, "model_size": 1922.160645, "workspace_size": 213.716309, "tstamp": 1665352932.4}
{"network": "roberta-base", "algorithm": null, "batch_size": 136, "layer_num": 12, "hidden_size": 768, "peak": 12245.856934, "total": 12016.669373, "activation": 10100.756836, "model_size": 1915.645447, "workspace_size": 229.187561, "tstamp": 1665352962.59}
{"network": "roberta-base", "algorithm": null, "batch_size": 144, "layer_num": 12, "hidden_size": 768, "peak": 12821.20459, "total": 12578.669312, "activation": 10639.131836, "model_size": 1939.254761, "workspace_size": 242.535278, "tstamp": 1665352993.17}
{"network": "roberta-base", "algorithm": null, "batch_size": 152, "layer_num": 12, "hidden_size": 768, "peak": 13442.052246, "total": 13184.91925, "activation": 11258.006836, "model_size": 1926.614075, "workspace_size": 257.132996, "tstamp": 1665353023.86}
{"network": "roberta-base", "algorithm": null, "batch_size": 160, "layer_num": 12, "hidden_size": 768, "peak": 13978.524902, "total": 13710.419189, "activation": 11782.756836, "model_size": 1927.348389, "workspace_size": 268.105713, "tstamp": 1665353054.19}
{"network": "roberta-base", "algorithm": null, "batch_size": 168, "layer_num": 12, "hidden_size": 768, "peak": 14630.372559, "total": 14346.419128, "activation": 12418.256836, "model_size": 1927.832703, "workspace_size": 283.95343, "tstamp": 1665353084.36}
{"network": "roberta-large", "algorithm": null, "batch_size": 4, "layer_num": 24, "hidden_size": 1024, "peak": 4073.409668, "total": 4059.939911, "activation": 1348.732422, "model_size": 2711.199188, "workspace_size": 13.469757, "tstamp": 1665353199.79}
{"network": "roberta-large", "algorithm": null, "batch_size": 12, "layer_num": 24, "hidden_size": 1024, "peak": 5714.533691, "total": 5690.182037, "activation": 2962.982422, "model_size": 2727.17569, "workspace_size": 24.351654, "tstamp": 1665353232.95}
{"network": "roberta-large", "algorithm": null, "batch_size": 20, "layer_num": 24, "hidden_size": 1024, "peak": 9945.393555, "total": 9898.026703, "activation": 4436.638672, "model_size": 5461.34848, "workspace_size": 47.366852, "tstamp": 1665353265.98}
{"network": "roberta-large", "algorithm": null, "batch_size": 28, "layer_num": 24, "hidden_size": 1024, "peak": 11514.737793, "total": 11453.471954, "activation": 6020.591797, "model_size": 5432.824982, "workspace_size": 61.265839, "tstamp": 1665353298.47}
{"network": "roberta-large", "algorithm": null, "batch_size": 36, "layer_num": 24, "hidden_size": 1024, "peak": 13100.647949, "total": 13021.425018, "activation": 7561.544922, "model_size": 5459.809296, "workspace_size": 79.222931, "tstamp": 1665353331.61}
{"network": "bert-large-cased", "algorithm": "swap", "batch_size": 4, "layer_num": 24, "hidden_size": 1024, "peak": 2047.364746, "total": 1271.873993, "activation": 578.616211, "model_size": 693.245575, "workspace_size": 775.490753, "tstamp": 1665381800.67}
{"network": "bert-large-cased", "algorithm": "swap", "batch_size": 12, "layer_num": 24, "hidden_size": 1024, "peak": 3279.583984, "total": 2484.604401, "activation": 1791.34668, "model_size": 693.222076, "workspace_size": 794.979584, "tstamp": 1665381843.2}
{"network": "bert-large-cased", "algorithm": "swap", "batch_size": 20, "layer_num": 24, "hidden_size": 1024, "peak": 4445.794922, "total": 3629.334808, "activation": 2936.077148, "model_size": 693.198578, "workspace_size": 816.460114, "tstamp": 1665381886.06}
{"network": "bert-large-cased", "algorithm": "swap", "batch_size": 28, "layer_num": 24, "hidden_size": 1024, "peak": 5549.005859, "total": 4743.565216, "activation": 4050.307617, "model_size": 693.175079, "workspace_size": 805.440643, "tstamp": 1665381930.3}
{"network": "bert-large-cased", "algorithm": "swap", "batch_size": 36, "layer_num": 24, "hidden_size": 1024, "peak": 6704.208496, "total": 5900.795624, "activation": 5207.538086, "model_size": 693.151581, "workspace_size": 803.412872, "tstamp": 1665381978.93}
{"network": "bert-large-cased", "algorithm": "swap", "batch_size": 44, "layer_num": 24, "hidden_size": 1024, "peak": 8032.419434, "total": 7221.026031, "activation": 6527.768555, "model_size": 693.128082, "workspace_size": 811.393402, "tstamp": 1665382026.27}
{"network": "bert-large-cased", "algorithm": "swap", "batch_size": 52, "layer_num": 24, "hidden_size": 1024, "peak": 9200.130371, "total": 8383.256439, "activation": 7689.999023, "model_size": 693.104584, "workspace_size": 816.873932, "tstamp": 1665382073.9}
{"network": "bert-large-cased", "algorithm": "swap", "batch_size": 60, "layer_num": 24, "hidden_size": 1024, "peak": 10414.841309, "total": 9590.486847, "activation": 8897.229492, "model_size": 693.081085, "workspace_size": 824.354462, "tstamp": 1665382121.79}
{"network": "bert-large-cased", "algorithm": "swap", "batch_size": 64, "layer_num": 24, "hidden_size": 1024, "peak": 10778.946777, "total": 9951.102051, "activation": 9257.844727, "model_size": 693.069336, "workspace_size": 827.844727, "tstamp": 1665382165.38}
{"network": "bert-large-cased", "algorithm": "swap", "batch_size": 72, "layer_num": 24, "hidden_size": 1024, "peak": 11943.158203, "total": 11108.332947, "activation": 10415.075195, "model_size": 693.045837, "workspace_size": 834.825256, "tstamp": 1665382208.53}
{"network": "bert-large-cased", "algorithm": "swap", "batch_size": 80, "layer_num": 24, "hidden_size": 1024, "peak": 13107.369141, "total": 12265.563354, "activation": 11572.305664, "model_size": 693.022339, "workspace_size": 841.805786, "tstamp": 1665382252.39}
{"network": "bert-large-cased", "algorithm": "swap", "batch_size": 88, "layer_num": 24, "hidden_size": 1024, "peak": 14272.580078, "total": 13423.793762, "activation": 12730.536133, "model_size": 692.99884, "workspace_size": 848.786316, "tstamp": 1665382296.13}
